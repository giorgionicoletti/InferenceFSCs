{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cdd35631-105c-47ca-8348-ad9499beb11c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a739250d-8f22-410a-9e56-326fc845ecaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import cm\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import numpy as np\n",
    "import random\n",
    "from scipy.special import softmax as softmax\n",
    "from math import ceil\n",
    "from IPython.display import display, clear_output\n",
    "from utils import *\n",
    "sm0 = nn.Softmax(dim = 0)\n",
    "sm1 = nn.Softmax(dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "93df2fcc-facb-40d0-9ab3-32ce5142aaa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = 2          #number of observations\n",
    "M = 2          #number of memory states\n",
    "A = 2          #number of actions\n",
    "F = 1 + 1      #number of linear features (+ bias)\n",
    "\n",
    "# optimizer parameters\n",
    "lr = 0.01\n",
    "n_epochs =10\n",
    "n_batch = 50\n",
    "threshold_act = 30\n",
    "dx = 125\n",
    "\n",
    "# trajectories limited?\n",
    "maxT = 5000 \n",
    "\n",
    "# shuffle gradient position\n",
    "x_pos_shuffle = False\n",
    "x_max_shuffle = 5\n",
    "\n",
    "# percentage of training data\n",
    "train_perc = 80\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cbf05adf-aa3b-497b-b535-bc15bc6c0aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the trajectories\n",
    "name_traj = \"./samples/trjs_N500len500test.pkl\"\n",
    "with open(name_traj, \"rb\") as f:\n",
    "    trjs_dict = pickle.load(f)\n",
    "\n",
    "# Splitting into train and test\n",
    "Neps = len(trjs_dict)\n",
    "Ntrain = int(Neps*train_perc/100)\n",
    "\n",
    "trjs_train = trjs_dict[:Ntrain]\n",
    "trjs_test = trjs_dict[Ntrain:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3412696f-a294-4df9-acbc-c1bb8ac7162c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c107dda1-b68f-441b-8327-9d7213f9598e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters for softmax policy\n",
    "# dims: {Y, M, M', A} \n",
    "# F = #features + bias\n",
    "\n",
    "#Start from a random theta ---default!\n",
    "theta = torch.rand( (F, M, M, A), requires_grad=True)\n",
    "theta.data = 2*theta.data-1\n",
    "theta.data /= 5\n",
    "\n",
    "\n",
    "#If you restart theta from a saved file\n",
    "theta_is_from_restart = False\n",
    "\n",
    "#If you start theta from a fixed set of numbers\n",
    "theta_is_fixed = False\n",
    "\n",
    "if theta_is_from_restart:\n",
    "    theta_restart_file = \"./results/virtual_data_antonio_FSC/theta_bacteria_FSC_M2_loglike431.11_th30_MselfconsTrue_FromRandom_FSCtrajs.dat\"\n",
    "    theta = torch.from_numpy(np.loadtxt(theta_restart_file).reshape(F,M,M,A))\n",
    "elif theta_is_fixed:\n",
    "    theta=np.array([[[[-0.61114431,-0.55987562],[ 0.59255672,0.82834098]],[[-0.88220033,0.46330714],[ 0.43192955,-0.52351326]]],\n",
    "               [[[ 0.41101729,-0.31575377],[-0.64954147,0.36582982]],[[-0.24503104,0.00449758],[ 0.8396274,0.59647384]]]])\n",
    "    theta=torch.from_numpy(theta.reshape(F,M,M,A))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5e9c681b-c7ea-4cca-a7bf-836458f3299a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameters for softmax of psi to get rho(m_0)\n",
    "psi=torch.rand(M,requires_grad=True)\n",
    "psi_uniform=False\n",
    "if psi_uniform:\n",
    "    psi=torch.ones(M,requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8ac66bff-30d3-4870-9969-dcc67385860f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sm0 = nn.Softmax(dim = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3e2275-d20f-48c3-aca0-fa80493cd1ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "364064b0-b13e-4e9d-9c26-87fe5fd0049b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 / 100\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Produce trajectories\n",
    "#ground_truth_theta=np.array([[[[-0.61114431,-0.55987562],[ 0.59255672,0.82834098]],[[-0.88220033,0.46330714],[ 0.43192955,-0.52351326]]], \n",
    "#[[[ 0.41101729,-0.31575377],[-0.64954147,0.36582982]],[[-0.24503104,0.00449758],[ 0.8396274,0.59647384]]]])\n",
    "\n",
    "\n",
    "Ntraj=100\n",
    "traj_len=500\n",
    "signal=get_signal_landscape('step_like',traj_len,Ntraj)\n",
    "dict_trajectories,original_theta = get_traj_from_theta(F,M,A,signal,'False',Ntraj,traj_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "75886077-7ee0-489b-9745-e75459c5460e",
   "metadata": {},
   "outputs": [],
   "source": [
    "trjs_dict=dict_trajectories\n",
    "# Splitting into train and test\n",
    "Neps = len(trjs_dict)\n",
    "Ntrain = int(Neps*train_perc/100)\n",
    "\n",
    "trjs_train = trjs_dict[:Ntrain]\n",
    "trjs_test = trjs_dict[Ntrain:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9abaff09-1211-4146-9c32-9096eee7a7ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[ 0.1140, -0.1474],\n",
       "           [ 0.1481, -0.0544]],\n",
       " \n",
       "          [[ 0.0145, -0.1954],\n",
       "           [-0.0065, -0.0348]]],\n",
       " \n",
       " \n",
       "         [[[-0.1033,  0.1056],\n",
       "           [ 0.1981,  0.1652]],\n",
       " \n",
       "          [[ 0.0161, -0.0139],\n",
       "           [ 0.0083, -0.1809]]]], requires_grad=True),\n",
       " tensor([0.8521, 0.8930], requires_grad=True))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta,psi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2fb7108-af05-412e-a75b-1716ca8c5481",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1/2: loss_psi 338.3437032047935\n",
      "Batch 2/2: loss_psi 338.171456945359645\n",
      "Epoch: 0 \tLoss train: 338.4796117071954 \tLoss test: 338.1714206523137\n",
      "Epoch: 0 \tLoss train: 338.2575800750766 \tLoss test: 338.1714206523137\n",
      "Batch 1/2: loss_psi 338.0321551718563\n",
      "Batch 2/2: loss_psi 337.891830299064057\n",
      "Epoch: 1 \tLoss train: 338.1017703479613 \tLoss test: 337.8917964500582\n",
      "Epoch: 1 \tLoss train: 337.96199273546017 \tLoss test: 337.8917964500582\n",
      "Batch 1/2: loss_psi 337.7478171498677\n",
      "Batch 2/2: loss_psi 337.605264890144782\n",
      "Epoch: 2 \tLoss train: 337.81979047587583 \tLoss test: 337.6052334236887\n",
      "Epoch: 2 \tLoss train: 337.6765410200062 \tLoss test: 337.6052334236887\n",
      "Batch 1/2: loss_psi 337.4696191795514\n",
      "Batch 2/2: loss_psi 337.3451551954102673\n",
      "Epoch: 3 \tLoss train: 337.5374112084363 \tLoss test: 337.3451262945051\n",
      "Epoch: 3 \tLoss train: 337.4073871874808 \tLoss test: 337.3451262945051\n",
      "Batch 1/2: loss_psi 337.23473899811853\n",
      "Batch 2/2: loss_psi 337.1397484568553506\n",
      "Epoch: 4 \tLoss train: 337.2899188387232 \tLoss test: 337.13972212108644\n",
      "Epoch: 4 \tLoss train: 337.18724372748693 \tLoss test: 337.13972212108644\n"
     ]
    }
   ],
   "source": [
    "optimizer_theta = torch.optim.Adam([theta], lr=lr)\n",
    "optimizer_psi = torch.optim.Adam([psi], lr=lr)\n",
    "\n",
    "count = 0\n",
    "\n",
    "Neps = len(trjs_dict)\n",
    "\n",
    "lr_mav = 1. / Ntrain\n",
    "\n",
    "losses_train_theta = []\n",
    "losses_test_theta = []\n",
    "\n",
    "losses_train_psi = []\n",
    "losses_test_psi = []\n",
    "\n",
    "grad_required=True\n",
    "for epochs in range(n_epochs):\n",
    "\n",
    "    running_loss_theta = 0.\n",
    "    running_loss_psi = 0.\n",
    "    random.shuffle(trjs_train)\n",
    "\n",
    "    for ibatch, batch in enumerate(batched(trjs_train, n_batch)):\n",
    "        #if alternate_update:\n",
    "        # Update theta while keeping psi fixed\n",
    "        loss_theta = trajs_loss_eval(theta, psi.detach(), batch, trjs_train)\n",
    "        loss_theta.backward()\n",
    "        running_loss_theta += loss_theta.item()\n",
    "            \n",
    "        optimizer_theta.step()\n",
    "        optimizer_theta.zero_grad()\n",
    "        \n",
    "        \n",
    "        # Update theta while keeping psi fixed\n",
    "        loss_psi= trajs_loss_eval(theta.detach(), psi, batch, trjs_train)\n",
    "        loss_psi.backward()\n",
    "        running_loss_psi += loss_psi.item()\n",
    "            \n",
    "        optimizer_psi.step()\n",
    "        optimizer_psi.zero_grad()\n",
    "        \n",
    "        \n",
    "        print(f\"Batch {ibatch+1}/{ceil(Ntrain/n_batch)}: loss_psi {loss_psi.item()}\")\n",
    "        print(f\"Batch {ibatch+1}/{ceil(Ntrain/n_batch)}: loss_theta {loss_theta.item()}\", end='\\r')\n",
    "    \n",
    "    loss_test_theta = trajs_loss_eval(theta, psi.detach(), batch, trjs_train)\n",
    "    loss_test_psi = trajs_loss_eval(theta.detach(), psi, batch, trjs_train)\n",
    "    \n",
    "    print(f\"Epoch: {epochs} \\tLoss train: {running_loss_theta/ceil(Ntrain/n_batch)} \\tLoss test: {loss_test_psi}\")\n",
    "    print(f\"Epoch: {epochs} \\tLoss train: {running_loss_psi/ceil(Ntrain/n_batch)} \\tLoss test: {loss_test_theta}\")\n",
    "    losses_train_theta.append(running_loss_theta)\n",
    "    losses_train_psi.append(running_loss_psi)\n",
    "    losses_test_theta.append(loss_test_theta)\n",
    "    losses_test_psi.append(loss_test_psi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "91eb0281-f34f-4454-9276-d0654cc9a83a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4251afd8-54cc-4ccf-ba7b-950a4e2f1507",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
